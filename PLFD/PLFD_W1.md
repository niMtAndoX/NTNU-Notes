# Overview
### Conceptiual Issues
* Any theory (or model) has two aspects:
1. explanation of past data (observations)
2. prediction of future (unobserved) data

* A model to acheive both goals (explaination and prediction) perfectly is not possible
* Important issues to be adressed:
&nbsp; - quality of explanation and prediction 
&nbsp; - is good prediction possible at all?
&nbsp; - if two models explain past data qually well, which one is better?
&nbsp; - how to measure model complexity

### Ockham's Razor
A problem solving principle which suggests that we should reduce assumptions to their minimum.

### Expected outcomes
#### Scientific / Technical
- Learning = generalization, concepts and issues
- Math theory: Statistical Learning Theory aka VC-Theory
- Conceptual basis vor various learning algorithms

#### Methodological
- How to use available statistical/machine learning/ data mining 
- How to compare prediction accuracy of different learning algorithms
- Are you getting good modeling results because you are smart or just lucky

#### Practical Applicaitons:
- Financial engineering
- Biomedical + Life Sciences
- Security
- Image recognition etc.

### Promise of Big Data
- More Data -> More knowledge

###
- Combines ideas/models and facts/data
- First principle knowledge:
&nbsp; hypothesis -> experiment -> theory
&nbsp; deterministic, casual, intelligible models

- Modern data-drien discovery:
&nbsp; s/w program + DATA -> knowledge
&nbsp; statistical, complex systems

- Many methodological differences

### Invariants of Scientific Knowledge
- Intelligent questions
- Non-trivial predictions
- Clear limitations / constraints
- All require human intelligence
&nbsp; - missing / lost in Big Data

### General Experimental Procedure
1. Statement of the Problem
2. Hypothesis Formulation (Problem Formalization) -  different from classical statistics
3. Data Generation / Experiment Design
4. Data Collection and Preprocessing
5. Model Estimation (learning)
6. Model Interpretation, Model Assessment ad Drawing Conclusions

Note: 
&nbsp; - each step is complex and requires several iterations
&nbsp; - estimated model depends on all previous steps
&nbsp; - observational data (not experimental design)

### Data Preprocessing and Scaling
- Preprocessing is required with observational data 
Examples:
- Basic preprocessing includes
&nbsp; - summary univariate statistics: mean, st. deviation, min+max value, range, boxplot performed independently for each input/output
&nbsp; - detection (removal) of outliers
&nbsp; - scaling of input/output variables (may be necessary for some learning algorithms)
- Visual inspection of data is tedious but useful

### Cultural + Ethical Aspects
- Cultural and business aspects usually affect:
&nbsp; - problem formalization
&nbsp; - data access / sharing (i.e., in life sciences)
&nbsp; - model interpretation

- Possible (idealistic) solution approach
&nbsp; - to adopt common methodology
&nbsp; - critical for interdisciplinary projects
